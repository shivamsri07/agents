{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7240ceef-b893-4934-8fcf-89500cad91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./venv/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: langchain_openai in ./venv/lib/python3.12/site-packages (0.3.16)\n",
      "Requirement already satisfied: langchain_anthropic in ./venv/lib/python3.12/site-packages (0.3.13)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langfuse\n",
      "  Downloading langfuse-2.60.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./venv/lib/python3.12/site-packages (from langgraph) (0.3.59)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in ./venv/lib/python3.12/site-packages (from langgraph) (2.0.25)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in ./venv/lib/python3.12/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in ./venv/lib/python3.12/site-packages (from langgraph) (0.1.69)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./venv/lib/python3.12/site-packages (from langgraph) (2.11.4)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in ./venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in ./venv/lib/python3.12/site-packages (from langchain_openai) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.12/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.51.0 in ./venv/lib/python3.12/site-packages (from langchain_anthropic) (0.51.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.42)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in ./venv/lib/python3.12/site-packages (from langfuse) (4.9.0)\n",
      "Collecting backoff>=1.10.0 (from langfuse)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in ./venv/lib/python3.12/site-packages (from langfuse) (0.28.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in ./venv/lib/python3.12/site-packages (from langfuse) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in ./venv/lib/python3.12/site-packages (from langfuse) (24.2)\n",
      "Collecting wrapt<2.0,>=1.14 (from langfuse)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.51.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.51.0->langchain_anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.51.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.51.0->langchain_anthropic) (4.13.2)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in ./venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.12/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langfuse-2.60.4-py3-none-any.whl (275 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, SQLAlchemy, backoff, langfuse, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.40 backoff-2.2.1 langchain-0.3.25 langchain-text-splitters-0.3.8 langfuse-2.60.4 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain_openai langchain_anthropic langchain langfuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae332ce8-dc45-4559-a9c2-a6764d295563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a680784-94fd-4cc2-b123-315bf5318354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "\n",
    "    # Category of the email (inquiry, complaint, etc.)\n",
    "    email_category: Optional[str]\n",
    "\n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]\n",
    "\n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "    \n",
    "    # Response generation\n",
    "    email_draft: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6f7c59e-ced6-4e7e-9f31-ed248750fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NODES\n",
    "# Initialize our LLM\n",
    "model = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, analyze this email and determine if it is spam or legitimate.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    First, determine if this email is spam. If it is spam, explain why.\n",
    "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    response_text = response.content.lower()\n",
    "    is_spam = \"spam\" in response_text and \"not spam\" not in response_text\n",
    "    \n",
    "    # Extract a reason if it's spam\n",
    "    spam_reason = None\n",
    "    if is_spam and \"reason:\" in response_text:\n",
    "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
    "    \n",
    "    # Determine category if legitimate\n",
    "    email_category = None\n",
    "    if not is_spam:\n",
    "        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]\n",
    "        for category in categories:\n",
    "            if category in response_text:\n",
    "                email_category = category\n",
    "                break\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason']}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    category = state[\"email_category\"] or \"general\"\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"email_draft\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_hugg(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Category: {state['email_category']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"email_draft\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf780359-5f82-4411-a20a-b56301701f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDGES\n",
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e127e27c-96d6-4629-8dd5-fc8f149b9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)\n",
    "email_graph.add_node(\"classify_email\", classify_email)\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)\n",
    "email_graph.add_node(\"draft_response\", draft_response)\n",
    "email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)\n",
    "\n",
    "# Start the edges\n",
    "email_graph.add_edge(START, \"read_email\")\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",\n",
    "        \"legitimate\": \"draft_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)\n",
    "email_graph.add_edge(\"draft_response\", \"notify_mr_hugg\")\n",
    "email_graph.add_edge(\"notify_mr_hugg\", END)\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c554f1c-c70f-4b3d-bc3b-67eac202ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from john.smith@example.com.\n",
      "Subject: Question about your services\n",
      "Category: inquiry\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Dear Mr. Smith,\n",
      "\n",
      "Thank you for your interest in Mr. Hugg's consulting services. On behalf of Mr. Hugg, I would like to acknowledge receipt of your inquiry. \n",
      "\n",
      "Mr. Hugg appreciates you reaching out and would be delighted to discuss how his services may benefit you and your organization. I will share your request with him and one of us will follow up with you shortly to arrange a mutually convenient time for a call next week.\n",
      "\n",
      "Please don't hesitate to let us know if you have any other questions in the meantime. We look forward to speaking with you further.\n",
      "\n",
      "Best regards,\n",
      "Alfred\n",
      "Assistant to Mr. Hugg\n",
      "\n",
      "How's this, sir? Please feel free to modify as you see fit before sending. I aimed to strike a cordial and professional tone while confirming next steps. I'm happy to revise the email if you would like any changes made.\n",
      "\n",
      "Regards,\n",
      "Alfred\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processing spam email...\n",
      "Alfred is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "Alfred has marked the email as spam. Reason: None\n",
      "The email has been moved to the spam folder.\n"
     ]
    }
   ],
   "source": [
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}\n",
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process the spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d1990d-7be6-43b0-852d-6f274818246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-52d13bb8-de1e-4e75-b663-501d0ca0f095\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-3cd5f4a6-4dcf-456d-91ad-5f27f18d5b76\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a01e4501-b228-476f-83a3-a8acb0066af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7 validation errors for UpdateGenerationBody\n",
      "usageDetails -> server_tool_use\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "usageDetails -> prompt_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> completion_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> input_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> output_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shivam/Desktop/agents/venv/lib/python3.12/site-packages/langfuse/client.py\", line 2739, in update\n",
      "    request = UpdateGenerationBody(**generation_body)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shivam/Desktop/agents/venv/lib/python3.12/site-packages/pydantic/v1/main.py\", line 347, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 7 validation errors for UpdateGenerationBody\n",
      "usageDetails -> server_tool_use\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "usageDetails -> prompt_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> completion_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> input_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> output_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "7 validation errors for UpdateGenerationBody\n",
      "usageDetails -> server_tool_use\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "usageDetails -> prompt_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> completion_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> input_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> output_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shivam/Desktop/agents/venv/lib/python3.12/site-packages/langfuse/client.py\", line 2739, in update\n",
      "    request = UpdateGenerationBody(**generation_body)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shivam/Desktop/agents/venv/lib/python3.12/site-packages/pydantic/v1/main.py\", line 347, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 7 validation errors for UpdateGenerationBody\n",
      "usageDetails -> server_tool_use\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "usageDetails -> prompt_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> completion_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> input_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> output_tokens\n",
      "  field required (type=value_error.missing)\n",
      "usageDetails -> total_tokens\n",
      "  field required (type=value_error.missing)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Sir, you've received an email from john.smith@example.com.\n",
      "Subject: Question about your services\n",
      "Category: inquiry\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Dear Mr. Smith,\n",
      "\n",
      "Thank you for your inquiry regarding Mr. Hugg's consulting services. On behalf of Mr. Hugg, I would like to express our appreciation for your colleague's referral and your interest in our offerings. \n",
      "\n",
      "Mr. Hugg would be delighted to discuss how his consulting expertise can benefit your organization. I have taken the liberty of checking his calendar for the upcoming week. Would a phone call on Tuesday, June 6th at 10:30 AM work well with your schedule? If not, please let me know a few alternative dates and times, and I will do my best to accommodate your preferences.\n",
      "\n",
      "Please feel free to contact me if you have any other questions in the meantime. We look forward to the opportunity to learn more about your needs and explore how Mr. Hugg can be of service.\n",
      "\n",
      "Best regards,\n",
      "Alfred Peterson\n",
      "Executive Assistant to Mr. Thomas Hugg\n",
      "\n",
      "How's this, sir? Please let me know if you would like me to modify anything in the message before sending it to Mr. Smith. I'm happy to revise it further to ensure it meets your preferences and captures the appropriate tone for this potential client engagement.\n",
      "\n",
      "Regards,\n",
      "Alfred\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Process legitimate email\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\"email\": legitimate_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
